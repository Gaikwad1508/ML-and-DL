{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "073e9933-1507-47c1-ab24-36b5ca0bbae7",
   "metadata": {},
   "source": [
    "## Building an Image Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5af8bd4f-93a7-4165-8c34-31e475faa0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "281f8829-7e02-4b5d-8e15-770aa74eeec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "887c1776-0eca-4dc2-b4fb-31f73ae2f8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63743ba2-aad3-46e2-942e-b4e86a6dcaf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3f6f3f-f27a-4b5c-ad3a-fd233792f9e4",
   "metadata": {},
   "source": [
    "Dataset of 60,000 28x28 grayscale images of 10 fashion categories, along with a test set of 10,000 imagaes. \n",
    "\n",
    "__Usage:\n",
    "from keras datasets import fashion_mnist\n",
    "    (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "Returns 2 tuples:\n",
    "    1. x_train, x_test: unit8 array of grayscale image data with shape (num_samples, 28, 28)\n",
    "    2. y_train, y_test: unit8 array of lables (integers in range 0-9)with shape (num_samples.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6555b26-57ea-4d87-bd77-d2cb5d531a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(x_train_full, y_train_full), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a46b07fa-82d6-48a4-8a70-fbe4cd7393f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2505f50f010>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.imshow(x_train_full[1])   #There are 10 items which represents no. from 0 to 9 for each item. So according to this example the item present in dataset at 0 location is the item which represents the 8 number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a017d1da-342e-4114-a449-fc8a7c192aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_full[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dff8fe9-38d4-4f7c-8a48-310543db4b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\",  \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bbeee1e-5b7c-44bc-8564-ba749ae3a399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'T-shirt/top'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train_full[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59a0a8a1-e835-41b4-bc1a-6c0f3aa2030e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,  11, 142, 200, 106,   0,   0,\n",
       "          0,   0,   0,   0,   0,  85, 185, 112,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 152, 214, 217, 194, 236, 216, 187,\n",
       "        149, 135, 153, 211, 217, 231, 205, 217, 188,  34,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,  66, 185, 166, 180, 181, 190, 211, 221,\n",
       "        197, 146, 198, 206, 191, 168, 190, 172, 188, 175,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0, 135, 153, 160, 175, 180, 170, 186, 187,\n",
       "        190, 188, 190, 187, 174, 195, 185, 174, 161, 175,  59,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0, 161, 147, 160, 170, 178, 177, 180, 168,\n",
       "        173, 174, 171, 185, 184, 185, 172, 171, 164, 174, 120,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   2, 175, 146, 145, 168, 178, 181, 185, 180,\n",
       "        184, 178, 179, 187, 191, 193, 190, 181, 171, 172, 158,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  35, 177, 155, 140, 151, 172, 191, 187, 186,\n",
       "        187, 186, 187, 182, 191, 194, 188, 180, 161, 161, 185,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  59, 170, 153, 141, 120, 154, 160, 161, 172,\n",
       "        168, 166, 161, 165, 172, 170, 164, 139, 149, 162, 166,  21,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  79, 145, 160, 214, 123, 128, 153, 160, 164,\n",
       "        158, 157, 154, 155, 170, 165, 141, 195, 193, 152, 166,  61,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 100, 157, 225, 245, 175, 113, 174, 158, 158,\n",
       "        160, 155, 160, 164, 178, 188, 135, 185, 240, 201, 172, 108,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,  31, 174,  28, 126, 153, 166, 152, 158,\n",
       "        158, 160, 161, 157, 168, 191, 188,  18, 132, 159,   7,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  82, 187, 159, 153, 157,\n",
       "        158, 162, 164, 164, 154, 187, 190,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   1,   3,   5,   0,  37, 175, 158, 155, 162,\n",
       "        158, 160, 162, 165, 153, 177, 205,   0,   0,   3,   3,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   1,   0,  25, 175, 152, 160, 158,\n",
       "        161, 160, 164, 164, 161, 166, 200,   0,   0,   1,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   4,   0,  30, 171, 147, 164, 155,\n",
       "        165, 161, 165, 162, 170, 164, 162,   0,   0,   2,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   4,   0,  57, 166, 155, 164, 166,\n",
       "        161, 161, 164, 167, 165, 165, 162,  28,   0,   3,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   3,   0, 114, 161, 161, 166, 159,\n",
       "        168, 161, 161, 172, 162, 165, 171,  50,   0,   5,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   1,   0, 149, 157, 167, 172, 159,\n",
       "        172, 164, 161, 172, 170, 160, 171,  89,   0,   4,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   2,   0,   4, 171, 164, 166, 173, 159,\n",
       "        179, 166, 160, 174, 167, 162, 166, 128,   0,   2,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   3,   0,  18, 152, 173, 160, 179, 154,\n",
       "        181, 166, 164, 175, 170, 166, 170, 164,   0,   0,   1,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   4,   0,  47, 165, 172, 167, 185, 153,\n",
       "        187, 173, 165, 174, 179, 166, 166, 158,   5,   0,   3,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   4,   0,  87, 180, 162, 179, 179, 157,\n",
       "        191, 182, 165, 168, 190, 173, 165, 166,  20,   0,   4,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   4,   0, 105, 187, 157, 194, 175, 161,\n",
       "        190, 184, 170, 158, 205, 177, 168, 171,  44,   0,   4,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   5,   0, 138, 181, 158, 205, 160, 167,\n",
       "        190, 198, 167, 152, 218, 186, 170, 172,  57,   0,   5,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   5,   0, 135, 174, 167, 199, 155, 166,\n",
       "        201, 219, 165, 158, 218, 188, 167, 175,  56,   0,   7,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   5,   0, 129, 171, 172, 177, 153, 159,\n",
       "        206, 216, 148, 157, 206, 190, 165, 175,  48,   0,   5,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   5,   0, 167, 187, 182, 198, 194, 200,\n",
       "        226, 240, 184, 206, 255, 197, 178, 179,  42,   0,   5,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   3,   0, 115, 135, 113, 106,  85,  82,\n",
       "        108, 133,  83,  90, 121, 120, 110, 158,  18,   0,   3,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_full[10]       #It represents the pixel values of image present at 10th index of x_train_full with 28 rows and 28 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e4ef2f-b2f0-424c-a852-63b5c0453187",
   "metadata": {},
   "source": [
    "## Data Normalization\n",
    "* For running gradient descent model we need to normalize the data first between 0 and 1\n",
    "* We then normalizing the data dimensions so that they are of approximately the same scale.\n",
    "* For normalizing data we divide all the values by max value present in data\n",
    "* As we know in given dataset the values are present in the scale of 0 to 255. so we can directly dividing it by max value i.e. 255\n",
    "* But for general databases we don't know about absolute scale so we generally subtract the mean from these no.s and divided by their standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "845634b9-ad52-4c72-acca-cb43ed88c588",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_n = x_train_full / 255.\n",
    "x_test_n = x_test / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d812ab02-b0c1-45b5-b8b8-3d44d09fcf2f",
   "metadata": {},
   "source": [
    "## Split the data into train/validation/test datasets\n",
    "In the earlier step of importing the data. We had 60,000 datasets for training and 10,000 test datasets. Now we know further split the trianing data into train/validation. Here is how each type of dataset is used in deep learning.\n",
    "\n",
    "    * Training data : Used for training the model.\n",
    "    * Validation data: Used for tuning the hyperparameters and evaluate the models.\n",
    "    * Test data: Used to test the model after the model has gone through initial vetting by the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "586f8cdf-b99a-4baa-af35-3ea734f7fe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid, x_train = x_train_n[: 5000], x_train_n[5000: ]\n",
    "y_valid, y_train = y_train_full[: 5000], y_train_full[5000: ]\n",
    "x_test = x_test_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b16ced4f-e9ac-46db-8003-47cc0c2ae750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00392157, 0.        , 0.        ,\n",
       "        0.05098039, 0.28627451, 0.        , 0.        , 0.00392157,\n",
       "        0.01568627, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00392157, 0.00392157, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.        , 0.14117647,\n",
       "        0.53333333, 0.49803922, 0.24313725, 0.21176471, 0.        ,\n",
       "        0.        , 0.        , 0.00392157, 0.01176471, 0.01568627,\n",
       "        0.        , 0.        , 0.01176471],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.02352941, 0.        , 0.4       ,\n",
       "        0.8       , 0.69019608, 0.5254902 , 0.56470588, 0.48235294,\n",
       "        0.09019608, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.04705882, 0.03921569, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.60784314,\n",
       "        0.9254902 , 0.81176471, 0.69803922, 0.41960784, 0.61176471,\n",
       "        0.63137255, 0.42745098, 0.25098039, 0.09019608, 0.30196078,\n",
       "        0.50980392, 0.28235294, 0.05882353],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00392157, 0.        , 0.27058824, 0.81176471,\n",
       "        0.8745098 , 0.85490196, 0.84705882, 0.84705882, 0.63921569,\n",
       "        0.49803922, 0.4745098 , 0.47843137, 0.57254902, 0.55294118,\n",
       "        0.34509804, 0.6745098 , 0.25882353],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "        0.00392157, 0.00392157, 0.        , 0.78431373, 0.90980392,\n",
       "        0.90980392, 0.91372549, 0.89803922, 0.8745098 , 0.8745098 ,\n",
       "        0.84313725, 0.83529412, 0.64313725, 0.49803922, 0.48235294,\n",
       "        0.76862745, 0.89803922, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.71764706, 0.88235294,\n",
       "        0.84705882, 0.8745098 , 0.89411765, 0.92156863, 0.89019608,\n",
       "        0.87843137, 0.87058824, 0.87843137, 0.86666667, 0.8745098 ,\n",
       "        0.96078431, 0.67843137, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.75686275, 0.89411765,\n",
       "        0.85490196, 0.83529412, 0.77647059, 0.70588235, 0.83137255,\n",
       "        0.82352941, 0.82745098, 0.83529412, 0.8745098 , 0.8627451 ,\n",
       "        0.95294118, 0.79215686, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "        0.01176471, 0.        , 0.04705882, 0.85882353, 0.8627451 ,\n",
       "        0.83137255, 0.85490196, 0.75294118, 0.6627451 , 0.89019608,\n",
       "        0.81568627, 0.85490196, 0.87843137, 0.83137255, 0.88627451,\n",
       "        0.77254902, 0.81960784, 0.20392157],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02352941, 0.        , 0.38823529, 0.95686275, 0.87058824,\n",
       "        0.8627451 , 0.85490196, 0.79607843, 0.77647059, 0.86666667,\n",
       "        0.84313725, 0.83529412, 0.87058824, 0.8627451 , 0.96078431,\n",
       "        0.46666667, 0.65490196, 0.21960784],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.01568627,\n",
       "        0.        , 0.        , 0.21568627, 0.9254902 , 0.89411765,\n",
       "        0.90196078, 0.89411765, 0.94117647, 0.90980392, 0.83529412,\n",
       "        0.85490196, 0.8745098 , 0.91764706, 0.85098039, 0.85098039,\n",
       "        0.81960784, 0.36078431, 0.        ],\n",
       "       [0.        , 0.        , 0.00392157, 0.01568627, 0.02352941,\n",
       "        0.02745098, 0.00784314, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.92941176, 0.88627451, 0.85098039,\n",
       "        0.8745098 , 0.87058824, 0.85882353, 0.87058824, 0.86666667,\n",
       "        0.84705882, 0.8745098 , 0.89803922, 0.84313725, 0.85490196,\n",
       "        1.        , 0.30196078, 0.        ],\n",
       "       [0.        , 0.01176471, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.24313725,\n",
       "        0.56862745, 0.8       , 0.89411765, 0.81176471, 0.83529412,\n",
       "        0.86666667, 0.85490196, 0.81568627, 0.82745098, 0.85490196,\n",
       "        0.87843137, 0.8745098 , 0.85882353, 0.84313725, 0.87843137,\n",
       "        0.95686275, 0.62352941, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.07058824,\n",
       "        0.17254902, 0.32156863, 0.41960784, 0.74117647, 0.89411765,\n",
       "        0.8627451 , 0.87058824, 0.85098039, 0.88627451, 0.78431373,\n",
       "        0.80392157, 0.82745098, 0.90196078, 0.87843137, 0.91764706,\n",
       "        0.69019608, 0.7372549 , 0.98039216, 0.97254902, 0.91372549,\n",
       "        0.93333333, 0.84313725, 0.        ],\n",
       "       [0.        , 0.22352941, 0.73333333, 0.81568627, 0.87843137,\n",
       "        0.86666667, 0.87843137, 0.81568627, 0.8       , 0.83921569,\n",
       "        0.81568627, 0.81960784, 0.78431373, 0.62352941, 0.96078431,\n",
       "        0.75686275, 0.80784314, 0.8745098 , 1.        , 1.        ,\n",
       "        0.86666667, 0.91764706, 0.86666667, 0.82745098, 0.8627451 ,\n",
       "        0.90980392, 0.96470588, 0.        ],\n",
       "       [0.01176471, 0.79215686, 0.89411765, 0.87843137, 0.86666667,\n",
       "        0.82745098, 0.82745098, 0.83921569, 0.80392157, 0.80392157,\n",
       "        0.80392157, 0.8627451 , 0.94117647, 0.31372549, 0.58823529,\n",
       "        1.        , 0.89803922, 0.86666667, 0.7372549 , 0.60392157,\n",
       "        0.74901961, 0.82352941, 0.8       , 0.81960784, 0.87058824,\n",
       "        0.89411765, 0.88235294, 0.        ],\n",
       "       [0.38431373, 0.91372549, 0.77647059, 0.82352941, 0.87058824,\n",
       "        0.89803922, 0.89803922, 0.91764706, 0.97647059, 0.8627451 ,\n",
       "        0.76078431, 0.84313725, 0.85098039, 0.94509804, 0.25490196,\n",
       "        0.28627451, 0.41568627, 0.45882353, 0.65882353, 0.85882353,\n",
       "        0.86666667, 0.84313725, 0.85098039, 0.8745098 , 0.8745098 ,\n",
       "        0.87843137, 0.89803922, 0.11372549],\n",
       "       [0.29411765, 0.8       , 0.83137255, 0.8       , 0.75686275,\n",
       "        0.80392157, 0.82745098, 0.88235294, 0.84705882, 0.7254902 ,\n",
       "        0.77254902, 0.80784314, 0.77647059, 0.83529412, 0.94117647,\n",
       "        0.76470588, 0.89019608, 0.96078431, 0.9372549 , 0.8745098 ,\n",
       "        0.85490196, 0.83137255, 0.81960784, 0.87058824, 0.8627451 ,\n",
       "        0.86666667, 0.90196078, 0.2627451 ],\n",
       "       [0.18823529, 0.79607843, 0.71764706, 0.76078431, 0.83529412,\n",
       "        0.77254902, 0.7254902 , 0.74509804, 0.76078431, 0.75294118,\n",
       "        0.79215686, 0.83921569, 0.85882353, 0.86666667, 0.8627451 ,\n",
       "        0.9254902 , 0.88235294, 0.84705882, 0.78039216, 0.80784314,\n",
       "        0.72941176, 0.70980392, 0.69411765, 0.6745098 , 0.70980392,\n",
       "        0.80392157, 0.80784314, 0.45098039],\n",
       "       [0.        , 0.47843137, 0.85882353, 0.75686275, 0.70196078,\n",
       "        0.67058824, 0.71764706, 0.76862745, 0.8       , 0.82352941,\n",
       "        0.83529412, 0.81176471, 0.82745098, 0.82352941, 0.78431373,\n",
       "        0.76862745, 0.76078431, 0.74901961, 0.76470588, 0.74901961,\n",
       "        0.77647059, 0.75294118, 0.69019608, 0.61176471, 0.65490196,\n",
       "        0.69411765, 0.82352941, 0.36078431],\n",
       "       [0.        , 0.        , 0.29019608, 0.74117647, 0.83137255,\n",
       "        0.74901961, 0.68627451, 0.6745098 , 0.68627451, 0.70980392,\n",
       "        0.7254902 , 0.7372549 , 0.74117647, 0.7372549 , 0.75686275,\n",
       "        0.77647059, 0.8       , 0.81960784, 0.82352941, 0.82352941,\n",
       "        0.82745098, 0.7372549 , 0.7372549 , 0.76078431, 0.75294118,\n",
       "        0.84705882, 0.66666667, 0.        ],\n",
       "       [0.00784314, 0.        , 0.        , 0.        , 0.25882353,\n",
       "        0.78431373, 0.87058824, 0.92941176, 0.9372549 , 0.94901961,\n",
       "        0.96470588, 0.95294118, 0.95686275, 0.86666667, 0.8627451 ,\n",
       "        0.75686275, 0.74901961, 0.70196078, 0.71372549, 0.71372549,\n",
       "        0.70980392, 0.69019608, 0.65098039, 0.65882353, 0.38823529,\n",
       "        0.22745098, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15686275, 0.23921569, 0.17254902,\n",
       "        0.28235294, 0.16078431, 0.1372549 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08621ad4-32b0-4043-830a-7b4e7de94bd5",
   "metadata": {},
   "source": [
    "## Create the model architecture \n",
    "There are two API's for defining a model in keras.\n",
    "\n",
    "    * Sequential model API:\n",
    "        used for straight forward networks like inputs are taken layer by layer. It means first layers output will be input for third layer not 4th or 5th layer.\n",
    "    \n",
    "    * Functional API:\n",
    "        used for complex networks like if we need the connect the input layer with something another hidden layer or any layer This model has this functionality. as it is more complex than sequential model api but it is flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2909dc6-0ecf-428f-a1f2-14f395d40695",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ccd351-5cfb-4eb8-baaa-9f20e613153e",
   "metadata": {},
   "source": [
    "* Input layer is 28x28 pixels we want out put as 10 categories.\n",
    "* as this is classification model so for hidden layers we are using ReLu Activation function and for Output layer Softmax Activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9bb6ac4-c701-4202-8929-99444b1fe636",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = [28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(100, activation = 'relu'))\n",
    "model.add(keras.layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517eb620-4776-4238-b0bf-e7fdd368ae47",
   "metadata": {},
   "source": [
    "*.add used for add the layer.\n",
    "* Flatten is used for convert the 2D array into 1D array.\n",
    "* .Dense is used for no. of neurons we want to make the layer with.\n",
    "* In classification model we use relu activation function for hidden layers and for output layer sofftmax activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "587ec0c2-5aa9-4bd6-9f22-5c05f8889806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43eeaa62-0fc5-4855-b8ba-fdf5dd4dcbcb",
   "metadata": {},
   "source": [
    "* In output shape we have not specified the class size so it has taken complete(  , 784), and neurons present in respective layers(  , 784.\n",
    "* param is the no. of variables that need to optimize. It is calculated like for dens_1 nerons are 100 and for above layer 300 so multiplying them and adding neurons no. equals 100 i.e present in dense_1 layer we get 30100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4584176-467f-470f-90ef-0070d9cf4a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pydot\n",
    "keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2a60ae-be38-4c85-87b8-ebbcd9c5775d",
   "metadata": {},
   "source": [
    "* We can access the parameters using get_weight() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74917caf-bd3c-459f-ab59-d69524c498cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93a79ba3-5b2a-42f8-818d-b686b154e7bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04060876,  0.02204017,  0.03948879, ..., -0.00728128,\n",
       "         0.06567287,  0.02502991],\n",
       "       [-0.00882311,  0.06943713, -0.01443269, ...,  0.02050226,\n",
       "         0.07276492,  0.02726627],\n",
       "       [-0.00086132,  0.04828868,  0.06842268, ..., -0.07043416,\n",
       "        -0.02511075, -0.00369278],\n",
       "       ...,\n",
       "       [-0.06458724, -0.04429334, -0.01946593, ...,  0.05366407,\n",
       "         0.01947147, -0.03320054],\n",
       "       [ 0.05797464, -0.05787864,  0.02468032, ..., -0.04274096,\n",
       "         0.04704432,  0.04586058],\n",
       "       [-0.01908545,  0.043661  ,  0.02798118, ...,  0.01958091,\n",
       "        -0.0652882 , -0.00953793]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6e4aec7-f3bd-47d4-b1ef-fd83bf5a8e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61f8c34f-0a8d-4d19-a425-3b37c76d5463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d23f6d05-8737-48fa-95ba-bf882e9e05b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25b8d5a-e883-4a17-bbc7-f77e5c24fdf8",
   "metadata": {},
   "source": [
    "* Before training our model we need to setup the learning processes and to do that we will use the compile method.\n",
    "* In our data we have 10 different labels so we are using sparse_categorical_crossentropy.\n",
    "* If instead we have probability per class in our y variable then we have to use categorical_crossentropy.\n",
    "* If we had binary labels such as yes or no , true or false in this case we have to use binary_crossentropy.\n",
    "* optimizer set to \"sgd\" it means stocastic gradient descent. in other words we are telling to keras to perform backpropogation algorithm.\n",
    "* As we are using classifier so metrix set to accuracy, if it is regression then it will be mean square error.\n",
    "* https://keras.io/api/models/sequential/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9380f31-6a18-4991-a770-966134758edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling our model\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\",\n",
    "              optimizer = \"sgd\",\n",
    "              metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "418ec7f1-9c9d-4177-b9b2-9b65edd30df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.7251 - accuracy: 0.7597 - val_loss: 0.5260 - val_accuracy: 0.8164\n",
      "Epoch 2/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4887 - accuracy: 0.8287 - val_loss: 0.4379 - val_accuracy: 0.8500\n",
      "Epoch 3/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4429 - accuracy: 0.8433 - val_loss: 0.5395 - val_accuracy: 0.8000\n",
      "Epoch 4/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.4161 - accuracy: 0.8543 - val_loss: 0.3977 - val_accuracy: 0.8630\n",
      "Epoch 5/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3973 - accuracy: 0.8604 - val_loss: 0.3807 - val_accuracy: 0.8660\n",
      "Epoch 6/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3794 - accuracy: 0.8664 - val_loss: 0.3721 - val_accuracy: 0.8700\n",
      "Epoch 7/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3670 - accuracy: 0.8703 - val_loss: 0.3680 - val_accuracy: 0.8754\n",
      "Epoch 8/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3555 - accuracy: 0.8741 - val_loss: 0.3867 - val_accuracy: 0.8624\n",
      "Epoch 9/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3443 - accuracy: 0.8782 - val_loss: 0.3614 - val_accuracy: 0.8718\n",
      "Epoch 10/30\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.3354 - accuracy: 0.8803 - val_loss: 0.3501 - val_accuracy: 0.8748\n",
      "Epoch 11/30\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.3271 - accuracy: 0.8833 - val_loss: 0.3455 - val_accuracy: 0.8794\n",
      "Epoch 12/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3182 - accuracy: 0.8857 - val_loss: 0.3329 - val_accuracy: 0.8824\n",
      "Epoch 13/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3108 - accuracy: 0.8879 - val_loss: 0.3316 - val_accuracy: 0.8836\n",
      "Epoch 14/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.3045 - accuracy: 0.8907 - val_loss: 0.3525 - val_accuracy: 0.8700\n",
      "Epoch 15/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2969 - accuracy: 0.8937 - val_loss: 0.3270 - val_accuracy: 0.8806\n",
      "Epoch 16/30\n",
      "1719/1719 [==============================] - 11s 6ms/step - loss: 0.2915 - accuracy: 0.8961 - val_loss: 0.3109 - val_accuracy: 0.8876\n",
      "Epoch 17/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2856 - accuracy: 0.8974 - val_loss: 0.3476 - val_accuracy: 0.8734\n",
      "Epoch 18/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2801 - accuracy: 0.8997 - val_loss: 0.3161 - val_accuracy: 0.8864\n",
      "Epoch 19/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2745 - accuracy: 0.9018 - val_loss: 0.3118 - val_accuracy: 0.8880\n",
      "Epoch 20/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2694 - accuracy: 0.9034 - val_loss: 0.3311 - val_accuracy: 0.8808\n",
      "Epoch 21/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2640 - accuracy: 0.9048 - val_loss: 0.3078 - val_accuracy: 0.8904\n",
      "Epoch 22/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2589 - accuracy: 0.9065 - val_loss: 0.2972 - val_accuracy: 0.8922\n",
      "Epoch 23/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2553 - accuracy: 0.9078 - val_loss: 0.3057 - val_accuracy: 0.8860\n",
      "Epoch 24/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2506 - accuracy: 0.9081 - val_loss: 0.3081 - val_accuracy: 0.8856\n",
      "Epoch 25/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2461 - accuracy: 0.9105 - val_loss: 0.3021 - val_accuracy: 0.8904\n",
      "Epoch 26/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2421 - accuracy: 0.9141 - val_loss: 0.3058 - val_accuracy: 0.8910\n",
      "Epoch 27/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2380 - accuracy: 0.9139 - val_loss: 0.2977 - val_accuracy: 0.8922\n",
      "Epoch 28/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2342 - accuracy: 0.9150 - val_loss: 0.2994 - val_accuracy: 0.8936\n",
      "Epoch 29/30\n",
      "1719/1719 [==============================] - 10s 6ms/step - loss: 0.2300 - accuracy: 0.9173 - val_loss: 0.3079 - val_accuracy: 0.8916\n",
      "Epoch 30/30\n",
      "1719/1719 [==============================] - 9s 5ms/step - loss: 0.2270 - accuracy: 0.9176 - val_loss: 0.3069 - val_accuracy: 0.8912\n"
     ]
    }
   ],
   "source": [
    "model_history = model.fit(x_train, y_train, epochs = 30, validation_data = (x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3fac5460-6011-4552-981e-085bf705bd0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 1, 'epochs': 30, 'steps': 1719}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a16d8fe-cd8a-4df0-ac01-c00c96c43a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tf_gpu_env)",
   "language": "python",
   "name": "tf_gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
